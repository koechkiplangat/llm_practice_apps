{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The first Kenyan President post independence was Jomo Kenyatta, who was in office from 1963 to 1978.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature = 0.6)\n",
    "\n",
    "name = \"Who was the first Kenyan President Post independence?\"\n",
    "\n",
    "print (llm(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Ugali\\n2. Nyama Choma (Grilled Meat)\\n3. Pilau\\n4. Irio\\n5. Chapati\\n6. Kuku Paka (Coconut Chicken Curry)\\n7. Mahamri (Coconut Doughnuts)\\n8. Mokimo (Mashed Potatoes)\\n9. Sambusa (Samosas)\\n10. Wali wa Nazi (Coconut Rice)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables= [\"country\"],\n",
    "    template=\"Give list of famous foods in {country}?\"\n",
    ")\n",
    "\n",
    "query = prompt.format(country = \"Kenya\")\n",
    "\n",
    "llm (query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nChelsea FC is a professional English football club based in Fulham, London. The club competes in the Premier League, the top tier of English football, and has won 18 top-flight titles, 13 FA Cups, five League Cups, and four FA Community Shields. Chelsea’s home ground is Stamford Bridge, where they have played since it opened in 1897. The club’s traditional kit colours are royal blue shirts and shorts with white socks.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=1)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"Arsenal\"],\n",
    "    template=\"what do you know of {football_team} ?\"\n",
    ")\n",
    "\n",
    "#query =  (prompt.format(football_team = \"ARSENAL\"))\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "\n",
    "chain.run(\"Chelsea FC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: google-search-results in c:\\users\\dc\\desktop\\langchain\\venv\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dc\\desktop\\langchain\\venv\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dc\\desktop\\langchain\\venv\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dc\\desktop\\langchain\\venv\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dc\\desktop\\langchain\\venv\\lib\\site-packages (from requests->google-search-results) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dc\\desktop\\langchain\\venv\\lib\\site-packages (from requests->google-search-results) (2023.7.22)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the president is and then calculate his age in 2023\n",
      "Action: Google\n",
      "Action Input: \"Kenyan President 2016\"\u001b[0m\n",
      "Observation: Google is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out who the president is and then calculate his age in 2023\n",
      "Action: Google\n",
      "Action Input: \"Uhuru Kenyatta Kenyan President\"\u001b[0m\n",
      "Observation: Google is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out who the president is and then calculate his age in 2023\n",
      "Action: Google\n",
      "Action Input: \"Uhuru Kenyatta Age\"\u001b[0m\n",
      "Observation: Google is not a valid tool, try one of [Calculator].\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to find out who the president is and then calculate his age in 2023\n",
      "Action: Google\n",
      "Action Input: \"Uhuru Kenyatta Father\"\u001b[0m\n",
      "Observation: Google is not a valid tool, try one of [Calculator].\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to find out who the president is and then calculate his age in 2023\n",
      "Action: Google\n",
      "Action Input: \"Uhuru Kenyatta Birthday\"\u001b[0m\n",
      "Observation: Google is not a valid tool, try one of [Calculator].\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-40ywDFkqgCnTW0X8QIq5WO1k on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\app\\ma.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DC/Desktop/LangChain/app/ma.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tools \u001b[39m=\u001b[39m load_tools([\u001b[39m\"\u001b[39m\u001b[39mllm-math\u001b[39m\u001b[39m\"\u001b[39m], llm\u001b[39m=\u001b[39mllm)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DC/Desktop/LangChain/app/ma.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m agent \u001b[39m=\u001b[39m initialize_agent(tools , llm,  agent\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzero-shot-react-description\u001b[39m\u001b[39m\"\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DC/Desktop/LangChain/app/ma.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mwho is the kenyan president as of 2016?, What will his age be in 2023? Who is his Father\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:505\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    506\u001b[0m         _output_key\n\u001b[0;32m    507\u001b[0m     ]\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    511\u001b[0m         _output_key\n\u001b[0;32m    512\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1146\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1146\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m   1147\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1148\u001b[0m         color_mapping,\n\u001b[0;32m   1149\u001b[0m         inputs,\n\u001b[0;32m   1150\u001b[0m         intermediate_steps,\n\u001b[0;32m   1151\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m   1152\u001b[0m     )\n\u001b[0;32m   1153\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1154\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m   1155\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m   1156\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:933\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    930\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m    932\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[0;32m    934\u001b[0m         intermediate_steps,\n\u001b[0;32m    935\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    936\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[0;32m    937\u001b[0m     )\n\u001b[0;32m    938\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:546\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39m    Action specifying what tool to use.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    545\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 546\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfull_inputs)\n\u001b[0;32m    547\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_parser\u001b[39m.\u001b[39mparse(full_output)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:298\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    284\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \n\u001b[0;32m    286\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:108\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    105\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m    106\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    107\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 108\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:120\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    118\u001b[0m callbacks \u001b[39m=\u001b[39m run_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m    121\u001b[0m         prompts,\n\u001b[0;32m    122\u001b[0m         stop,\n\u001b[0;32m    123\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    124\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[0;32m    125\u001b[0m     )\n\u001b[0;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mbind(stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs)\u001b[39m.\u001b[39mbatch(\n\u001b[0;32m    128\u001b[0m         cast(List, prompts), {\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[0;32m    129\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\llms\\base.py:507\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    500\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    501\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    505\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    506\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 507\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\llms\\base.py:656\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    642\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    643\u001b[0m         )\n\u001b[0;32m    644\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    646\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         )\n\u001b[0;32m    655\u001b[0m     ]\n\u001b[1;32m--> 656\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[0;32m    657\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    658\u001b[0m     )\n\u001b[0;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m    660\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\llms\\base.py:544\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[0;32m    543\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 544\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    545\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    546\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\llms\\base.py:531\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[0;32m    522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    523\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    528\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    529\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 531\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[0;32m    532\u001b[0m                 prompts,\n\u001b[0;32m    533\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    534\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    535\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    536\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    537\u001b[0m             )\n\u001b[0;32m    538\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    539\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    540\u001b[0m         )\n\u001b[0;32m    541\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    542\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\llms\\openai.py:401\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m     choices\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    390\u001b[0m         {\n\u001b[0;32m    391\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: generation\u001b[39m.\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m         }\n\u001b[0;32m    399\u001b[0m     )\n\u001b[0;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\n\u001b[0;32m    402\u001b[0m         \u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[0;32m    403\u001b[0m     )\n\u001b[0;32m    404\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    405\u001b[0m     update_token_usage(_keys, response, token_usage)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\langchain\\llms\\openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[1;32mc:\\Users\\DC\\Desktop\\LangChain\\venv\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39msleep(seconds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature = 0)\n",
    "\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(tools , llm,  agent=\"zero-shot-react-description\", verbose = True)\n",
    "\n",
    "agent.run(\"who is the kenyan president as of 2016?, What will his age be in 2023? Who is his Father\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
